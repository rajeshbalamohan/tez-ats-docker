{"paragraphs":[{"text":"/**\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n \nimport java.io._\n\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.tez.analyzer.plugins._\nimport org.apache.tez.history.parser._\nimport org.apache.tez.history.parser.datamodel.DagInfo\n\nimport scala.collection.JavaConversions._\n\n/**\n * \n * This zeppelin notebook is used for analyzing DagFiles downloaded via Tez-UI or via standalone ATSImportTool.\n * This notebook processe the dagFile and runs the DagInfo through a set of analyzers already pre-defined in Tez.\n * Results of analyzers are saved in RDD which are registered as tables in SparkSQL. This can be queried at runtime.\n * \n * Installation:\n * - Install latest version of zeppelin\n * - Compile tez master and copy all tez jar files to incubator-zeppelin/interpreter/spark/dep/\n * - Start zeppelin\n * - Import this notebook\n * - Install \"DOT\" in zeppelin machine to convert DOT file to PDF.\n * - Click on \"Run\" button in this paragrah\n *    - This should prompt input fields like \"dagFile\", \"dagName\", \"tmpDir\". Populate these fields and run again.\n * */\n\n  /**\n   * Get dagFile, dagName, tmpDir as inputs from end user\n   * */\n  //TODO: Carry out some error handling if on dagFile existence, dagName validation, tmpDir existence etc\n  var dagFile = z.input(\"dagFile\")\n  var dagName = z.input(\"dagName\")\n  var tmpDir = z.input(\"tmpDir\", \"\")\n\n  /**\n   * Define all classes needed for mapping to RDD\n   * */\n  case class VertexCriticalPath(CriticalPath: String, Score: String)\n\n  case class Shuffle(vertexName: String, taskAttemptId: String, Node: String,\n                counterGroup: String, Comments: String,\n                REDUCE_INPUT_GROUPS: String, REDUCE_INPUT_RECORDS: String,\n                ratio: String, SHUFFLE_BYTES: String, TotalTimeTaken: String,\n                TimeTaken_To_Receive_Events: String, MERGE_PHASE_TIME: String,\n                SHUFFLE_PHASE_TIME: String, TimeTaken_For_Real_Task: String,\n                FIRST_EVENT_RECEIVED: String, LAST_EVENT_RECEIVED: String,\n                SHUFFLE_BYTES_DISK_DIRECT: String)\n\n  case class Skew(vertexName: String, taskAttemptId: String,\n                counterGroup: String, node: String,\n                REDUCE_INPUT_GROUPS: String, REDUCE_INPUT_RECORDS: String,\n                input_records_to_group_ratio: String, SHUFFLE_BYTES: String,\n                timeTaken: String, observation: String)\n\n  case class SlowestVertex(vertexName: String, taskAttempts: String, totalTime: String,\n                shuffleTime: String, shuffleTime_Max: String,\n                LastEventReceived: String, LastEventReceivedFrom: String,\n                percentile_75: String, percentile95: String,\n                percentile_98: String, Median: String,\n                observation: String, comments: String)\n\n  case class SlowTask(vertexName: String, taskAttemptId: String, Node: String,\n                taskDuration: String, Status: String, diagnostics: String,\n                NoOfInputs: String)\n\n  case class Spill(vertexName: String, taskAttemptId: String, Node: String,\n                counterGroupName: String, spillCount: String, taskDuration: String,\n                OUTPUT_BYTES: String, OUTPUT_RECORDS: String, SPILLED_RECORDS: String,\n                Recommendation: String\n                )\n\n  case class SlowNode(nodeName: String, noOfTasksExecuted: String, noOfKilledTasks: String,\n                noOfFailedTasks: String, avgSucceededTaskExecutionTime: String,\n                avgKilledTaskExecutionTime: String, avgFailedTaskExecutionTime: String,\n                avgHDFSBytesRead: String, avgHDFSBytesWritten: String,\n                avgFileBytesRead: String, avgFileBytesWritten: String,\n                avgGCTimeMillis: String, avgCPUTimeMillis: String\n                )\n\n  case class TaskConcurrency(time: String, vertexName: String, concurrentTasksRunning: String)\n\n  case class ContainerReuse(vertexName: String, taskAttempts: String, node: String,\n                containerId: String, reuseCount: String)\n\n  case class Locality(vertexName: String, numTasks: String, dataLocalRatio: String,\n                rackLocalRatio: String, otherRatio: String, avgDataLocalTaskRuntime: String,\n                avgRackLocalTaskRuntime: String, avgOtherLocalTaskRuntime: String,\n                noOfInputs: String, avgHDFSBytesRead_DataLocal: String,\n                avgHDFSBytesRead_RackLocal: String, avgHDFSBytesRead_Others: String,\n                recommendation: String)\n\n    /**\n      * Load ATS data and parse it.\n      **/\n    var atsParser = new ATSFileParser(new File(dagFile.toString()));\n    var dagInfo = atsParser.getDAGData(dagName.toString());\n\n    println(\"Done with parsing  \" + dagInfo.toString + \", \" + tmpDir.toString())\n\n    val config = new Configuration\n    \n    // Vertex Level Critical Path Analysis\n    config.set(\"tez.critical-path.analyzer.dot.output.loc\", tmpDir.toString())\n    val vertexLevelCriticalPathAnalyzer = new VertexLevelCriticalPathAnalyzer(config)\n    vertexLevelCriticalPathAnalyzer.analyze(dagInfo)\n    val vcResult = vertexLevelCriticalPathAnalyzer.getResult.getRecordsIterator.map { record =>\n      VertexCriticalPath(record(0), record(1))\n    }\n    sc.makeRDD(vcResult.toSeq).toDF().registerTempTable(\"vertex_criticalPath_\" + dagName.toString())\n    \n    \n    // Critical Path analysis (generates graph in tmpDir)\n    config.set(\"output-dir\", tmpDir.toString())\n    config.set(\"tez.critical-path-analyzer.draw-svg\", \"true\")\n    val criticalPathAnalyzer = new CriticalPathAnalyzer(config)\n    criticalPathAnalyzer.setConf(config)\n    criticalPathAnalyzer.analyze(dagInfo)\n    val result = criticalPathAnalyzer.getResult // no additional mappings needed as it would generate SVG\n    \n    \n    // Shuffle Time Analysis\n    config.set(\"tez.shuffle-time-analyzer.real-work.done.ratio\", \"0.4\") /* Ratio of (total time - shuffle time) / (total time).*/\n    config.set(\"tez.shuffle-time-analyzer.shuffle.min.records\", \"100\") /*Filtering: num of min records that needs to be available as reduce input records*/\n    val shuffleTimeAnalyzer = new ShuffleTimeAnalyzer(config)\n    shuffleTimeAnalyzer.analyze(dagInfo)\n    val shuffleTimeAnalyzerResult = shuffleTimeAnalyzer.getResult.getRecordsIterator.map { s =>\n      Shuffle(s(0), s(1), s(2), s(3), s(4), s(5), s(6), s(7), s(8),\n        s(9), s(10), s(11), s(12), s(13), s(14), s(15), s(16))\n    }\n    sc.makeRDD(shuffleTimeAnalyzerResult.toSeq).toDF().registerTempTable(\"shuffle_time_analysis_\" + dagName.toString())\n    \n    \n    // Skew Analysis\n    config.set(\"tez.skew-analyzer.shuffle.bytes.per.source\", \"100000\")\n    config.set(\"tez.skew-analyzer.shuffle.key.group.min.ratio\", \"0.2\") /*Filtering: Min reducer input group : reducer keys ratio for computation*/\n    config.set(\"tez.skew-analyzer.shuffle.key.group.max.ratio\", \"0.6\") /*Filtering: Max reducer input group : reducer keys ratio for computation*/\n    val skewAnalyzer = new SkewAnalyzer(config)\n    skewAnalyzer.analyze(dagInfo)\n    val skewAnalyzerResult = skewAnalyzer.getResult.getRecordsIterator.map { s =>\n      Skew(s(0), s(1), s(2), s(3), s(4), s(5), s(6), s(7), s(8), s(9))\n    }\n    sc.makeRDD(skewAnalyzerResult.toSeq).toDF().registerTempTable(\"skew_analysis_\" + dagName.toString())\n    \n    \n    // Slow Vertex Analysis\n    config.setLong(\"tez.slowest-vertex-analyzer.max.vertex.runtime\", 50000) /* For demo. Anything > 50 seconds is considered slow */\n    val slowestVertexAnalyzer = new SlowestVertexAnalyzer(config)\n    slowestVertexAnalyzer.analyze(dagInfo)\n    val slowVertexResult = slowestVertexAnalyzer.getResult.getRecordsIterator.map { s =>\n      SlowestVertex(s(0), s(1), s(2), s(3), s(4), s(5), s(6), s(7),\n        s(8), s(9), s(10), s(11), s(12))\n    }\n    sc.makeRDD(slowVertexResult.toSeq).toDF().registerTempTable(\"slow_vertex_analysis_\" + dagName.toString())\n    \n    \n    // Slow Task Analysis\n    config.set(\"tez.slow-task-analyzer.task.count\", \"500000\") //how many tasks to pull\n    val slowTaskIdentifier = new SlowTaskIdentifier(config)\n    slowTaskIdentifier.analyze(dagInfo)\n    val slowTaskResult = slowTaskIdentifier.getResult.getRecordsIterator.map { s =>\n      SlowTask(s(0), s(1), s(2), s(3), s(4), s(5), s(6))\n    }\n    sc.makeRDD(slowTaskResult.toSeq).toDF().registerTempTable(\"slow_task_analysis_\" + dagName.toString())\n    \n    // Spill Analysis\n    config.set(\"tez.spill-analyzer.min.output.bytes.threshold\", \"50000\") //min amount of bytes that needs to be churned out by a task.\n    val spillAnalyzer = new SpillAnalyzerImpl(config)\n    spillAnalyzer.analyze(dagInfo)\n    val spillResult = spillAnalyzer.getResult.getRecordsIterator.map { s =>\n      Spill(s(0), s(1), s(2), s(3), s(4), s(5), s(6), s(7), s(8), s(9))\n    }\n    sc.makeRDD(spillResult.toSeq).toDF().registerTempTable(\"spill_analysis_\" + dagName.toString())\n    \n    \n    // Slow Node Analysis\n    val slowNodeAnalyzer = new SlowNodeAnalyzer(new Configuration())\n    slowNodeAnalyzer.analyze(dagInfo)\n    val slowNodeResult = slowNodeAnalyzer.getResult.getRecordsIterator.map { s =>\n      SlowNode(s(0), s(1), s(2), s(3), s(4), s(5), s(6), s(7)\n        , s(8), s(9), s(10), s(11), s(12))\n    }\n    sc.makeRDD(slowNodeResult.toSeq).toDF().registerTempTable(\"slow_node_analysis_\" + dagName.toString())\n    \n    \n    // Task Concurrency Analysis\n    config.setInt(\"tez.task-concurrency-analyzer.time.interval\", 5000)\n    val taskConcurrencyAnalyzer = new TaskConcurrencyAnalyzer(config)\n    taskConcurrencyAnalyzer.analyze(dagInfo)\n    val taskConcurrencyResult = taskConcurrencyAnalyzer.getResult.getRecordsIterator.map { s =>\n      TaskConcurrency(s(0), s(1), s(2))\n    }\n    sc.makeRDD(taskConcurrencyResult.toSeq).toDF().registerTempTable(\"task_concurrency_analysis_\" + dagName.toString())\n    \n    // Container Resuse Analysis\n    val containerReuseAnalyzer = new ContainerReuseAnalyzer(new Configuration())\n    containerReuseAnalyzer.analyze(dagInfo)\n    val containerReuseResult = containerReuseAnalyzer.getResult.getRecordsIterator.map { s =>\n      ContainerReuse(s(0), s(1), s(2), s(3), s(4))\n    }\n    sc.makeRDD(containerReuseResult.toSeq).toDF().registerTempTable(\"container_reuse_analysis_\" + dagName.toString())\n    \n    \n    // Locality Analysis\n    val localityAnalyzer = new LocalityAnalyzer(new Configuration())\n    localityAnalyzer.analyze(dagInfo)\n    val localityResult = localityAnalyzer.getResult.getRecordsIterator.map { s =>\n      Locality(s(0), s(1), s(2), s(3), s(4), s(5), s(6), s(7), s(8),\n        s(9), s(10), s(11), s(12))\n    }\n    sc.makeRDD(localityResult.toSeq).toDF().registerTempTable(\"locality_analysis_\" + dagName.toString())\n    \n    println(\"Created all tables for \" + dagName)\n","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":"dagName","tmpDir":"/dagFiles","dagFile":"/dagFiles/dagFileName.zip"},"forms":{"dagName":{"name":"dagName","displayName":"dagName","type":"input","defaultValue":"","hidden":false},"tmpDir":{"name":"tmpDir","displayName":"tmpDir","type":"input","defaultValue":"","hidden":false},"dagFile":{"name":"dagFile","displayName":"dagFile","type":"input","defaultValue":"","hidden":false}}},"jobName":"paragraph_1470997772793_-1215697257","id":"20160405-132729_1888198738","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:247"},{"title":"Critical Path Analyzer","text":"// Set MACHINE/HTML_DIR as per your environment. SVG would be placed in tmpDir listed in the above paragrah. It would be good to map that directory to the html folder.\nprintln(\"%html <img src='http://\" + java.net.InetAddress.getLocalHost().getHostName() + \"/dagFiles/\" + z.input(\"dagName\") + \".svg' alt='Critical Path Analyzer'>\")\n","dateUpdated":"2016-08-12T10:44:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"tmpDir":"dag_1449839819858_666490_1","dagName":""},"forms":{"dagName":{"name":"dagName","displayName":"dagName","type":"input","defaultValue":"","hidden":false}}},"jobName":"paragraph_1470997772795_-1214927759","id":"20160405-132729_356987213","result":{"code":"SUCCESS","type":"HTML","msg":"<img src='http://cn042-10.l42scl.hortonworks.com/dagFiles/.svg' alt='Critical Path Analyzer'>\n"},"dateCreated":"2016-08-12T10:29:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:248","dateFinished":"2016-08-12T10:44:20+0000","dateStarted":"2016-08-12T10:44:20+0000","focus":true},{"title":"Convert Dot To PDF (For CriticalPath Analyzer @ Vertex Level)","text":"%sh \n// Provide the same tmpDir location as in first paragraph. Zeppelin does not have the feature to share variables across different interpreters.\ndot -Tpdf /dagFiles/${dagName}.dot > /dagFiles/${dagName}.pdf\n","dateUpdated":"2016-08-12T10:46:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":false}}},"jobName":"paragraph_1470997772796_-1216851504","id":"20160405-132729_332133842","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:249"},{"title":"CriticalPath Analyzer @ Vertex Level","text":"// Set  MACHINE/HTML_DIR as per your environment. DOT would be placed in tmpDir listed in the above paragrah. It would be good to map that directory to the html folder.\n// DOT program is needed for it to generate PDF\nprintln(\"%html <object data='http://\" + java.net.InetAddress.getLocalHost().getHostName() + \"/\" + z.input(\"dagName\") + \".pdf' type='application/pdf' width='100%' height='500'><param name='view' value='fitH' /><p>It appears you don't have a PDF plugin for this browser. No biggie... you can <a href='http://machinename/dagFiles/\" + z.input(\"dagName\") + \".pdf'>click here to download the PDF file.</a></p></object>\")\n","dateUpdated":"2016-08-12T10:46:48+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","displayName":"dagName","type":"input","defaultValue":"","hidden":false}}},"jobName":"paragraph_1470997772796_-1216851504","id":"20160405-132729_159438004","result":{"code":"SUCCESS","type":"HTML","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:250"},{"title":"Slow Vertex Analyzer - Find Out Runtime Percentiles, Whether It Was Slow Due To Upstream Vertex / Straggler Etc","text":"%sql SELECT *\nFROM slow_vertex_analysis__${dagName}\nORDER BY cast(totalTime AS int) DESC","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772796_-1216851504","id":"20160405-132729_1302631489","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:251"},{"title":"TaskConcurrency Analyzer (Starvation Analysis) - Find Out How Slots Were Given/Used For Different Vertices","text":"%sql select (cast(time as bigint)) as time, vertexName, concurrentTasksRunning from task_concurrency_analysis__${dagName}","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"lineChart","height":300,"optionOpen":true,"keys":[{"name":"time","index":0,"aggr":"sum","$$hashKey":"object:267"}],"values":[{"name":"concurrentTasksRunning","index":2,"aggr":"avg","$$hashKey":"object:271"}],"groups":[{"name":"vertexName","index":1,"aggr":"sum","$$hashKey":"object:269"}],"scatter":{"xAxis":{"name":"time","index":0,"aggr":"sum"},"yAxis":{"name":"vertexName","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772797_-1217236252","id":"20160405-132729_1631918561","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:252"},{"title":"SlowTask Identifier - Query Slow Tasks At Every Vertex (Change SQL Filters Accordingly)","text":"%sql SELECT *\nFROM slow_task_analysis__${dagName}  -- For demo, try to analyze the straggler task from Map 5 identified above (notice most of all stragglers ran on same node cn058)\nORDER BY cast(taskDuration AS int) DESC LIMIT 100","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772797_-1217236252","id":"20160405-132729_770442622","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:253"},{"title":"Spill Analysis - Find Out If Any Spills Happened In The Task (Adjust Sort Buffer Accordingly)","text":"%sql SELECT vertexName,\n       taskAttemptId,\n       Node,\n       counterGroupName,\n       spillCount,\n       taskDuration,\n       OUTPUT_BYTES,\n       OUTPUT_BYTES,\n       SPILLED_RECORDS,\n       Recommendation\nFROM spill_analysis__${dagName} WHERE counterGroupName != 'org.apache.tez.common.counters.TaskCounter'\nORDER BY cast(taskDuration AS int) DESC LIMIT 1000","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772797_-1217236252","id":"20160405-132729_575033603","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:254"},{"title":"Skew Analyzer (For Shuffle) - To Understand Issues Related To Partitioner / Parallelism / Memory Issues Based On REDUCE_INPUT_GROUPS / REDUCE_INPUT_RECORDS","text":"%sql SELECT vertexName,\n       taskAttemptId,\n       counterGroup,\n       node,\n       SHUFFLE_BYTES,\n       timeTaken,\n       REDUCE_INPUT_GROUPS,\n       REDUCE_INPUT_RECORDS,\n       input_records_to_group_ratio,\n       observation\nFROM skew_analysis__${dagName}\nORDER BY cast(timeTaken AS int) DESC LIMIT 100","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"vertexName","index":0,"aggr":"sum"}],"values":[{"name":"taskAttemptId","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"vertexName","index":0,"aggr":"sum"},"yAxis":{"name":"taskAttemptId","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772798_-1216082006","id":"20160405-132729_1269424022","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:255"},{"title":"Shuffle Time Analysis @ Attempt Level","text":"%sql SELECT vertexName,\n       taskAttemptId,\n       counterGroup,\n       Node,\n       SHUFFLE_BYTES,\n       TotalTimeTaken,\n       TimeTaken_To_Receive_Events,\n       SHUFFLE_PHASE_TIME,\n       MERGE_PHASE_TIME,\n       TimeTaken_For_Real_Task,\n       FIRST_EVENT_RECEIVED,\n       LAST_EVENT_RECEIVED,\n       SHUFFLE_BYTES_DISK_DIRECT\nFROM shuffle_time_analysis__${dagName}\nWHERE counterGroup != 'org.apache.tez.common.counters.TaskCounter' -- AND (SHUFFLE_PHASE_TIME - LAST_EVENT_RECEIVED) > 10000  --(to demo if shuffle is slow due to last event received; ie higher vertex)\nORDER BY cast(SHUFFLE_PHASE_TIME AS int) DESC LIMIT 100","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772798_-1216082006","id":"20160405-132729_48909587","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:256"},{"title":"ShuffleVertexManager Slowstart Analysis (Whether Slow Start Is Needed Or Should Be Tuned Etc, Based On FIRST_EVENT_RECEVIED Vs LAST_EVENT_RECEIVED)","text":"%sql SELECT vertexName, -- This is just example. Change the query to suite your needs. Might want to try out at vertex level and tweak ShuffleVertexManager slowstart settings\n       taskAttemptId,\n       'This task got scheduled too soon. Ended up wasting slot' AS description,\n       Node,\n       ((LAST_EVENT_RECEIVED - FIRST_EVENT_RECEIVED) / TotalTimeTaken) AS wastageRatio\nFROM shuffle_time_analysis__${dagName}\nWHERE counterGroup != 'org.apache.tez.common.counters.TaskCounter'\n  AND ((LAST_EVENT_RECEIVED - FIRST_EVENT_RECEIVED) / TotalTimeTaken) > 0\nORDER BY cast(wastageRatio AS int) DESC LIMIT 100","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772798_-1216082006","id":"20160405-132729_1331720133","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:257"},{"title":"Container Preemption Diagnostics (E.G Find Number Of Prematurely Killed Task Attempts Done Via Scheduler. E.G Adjust Tez.Am.Preemption.Percentage)","text":"%sql SELECT vertexName,\n       \"Internal Container Pre-emption\" AS description,\n       count(*) AS totalPreemptionCount\nFROM slow_task_analysis__${dagName}\nWHERE DIAGNOSTICS LIKE '%preempted%'\n  AND status LIKE 'KILLED'\nGROUP BY vertexName -- May be we need to find the ratio of total attempts vs pre-emption to understand the wastage??","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772798_-1216082006","id":"20160405-132729_1597960547","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:258"},{"title":"Slow Nodes - Find Out If There Any Slow Nodes In The Cluster (Need To Co-Relate NoOfTasksExecuted Vs AvgTaskExecutionTime Vs BytesRead/Written)","text":"%sql SELECT nodeName,\n       noOfTasksExecuted,\n       noOfKilledTasks,\n       noOfFailedTasks,\n       avgSucceededTaskExecutionTime,\n       avgKilledTaskExecutionTime,\n       avgFailedTaskExecutionTime,\n       avgHDFSBytesRead,\n       avgHDFSBytesWritten,\n       avgFileBytesRead,\n       avgFileBytesWritten,\n       avgGCTimeMillis,\n       avgCPUTimeMillis\nFROM slow_node_analysis__${dagName} ORDER BY cast(avgSucceededTaskExecutionTime as int) DESC,  cast(noOfTasksExecuted as int) DESC ","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772799_-1216466755","id":"20160405-132729_1517207677","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:259"},{"title":"ContainerReuse Information","text":"%sql SELECT containerId,\n       node,\n       sum(reuseCount) AS reuse\nFROM container_reuse_analysis__${dagName}\nGROUP BY containerId,\n         node\nORDER BY reuse DESC LIMIT 10","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772799_-1216466755","id":"20160405-132729_171744502","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:260"},{"title":"Locality Analysis - Whether Locality Issues Ended Up Affecting The Job/Vertex Time","text":"%sql SELECT *\nFROM locality_analysis__${dagName}\nORDER BY numTasks DESC","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772799_-1216466755","id":"20160405-132729_1190057011","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:261"},{"title":"Slow Vertex Analyzer - Find Out Runtime Percentiles, Whether It Was Slow Due To Upstream Vertex / Straggler Etc","text":"%sql SELECT *\nFROM  vertex_criticalpath__${dagName}\t\t\nORDER BY SCORE","dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"CriticalPath","index":0,"aggr":"sum"}],"values":[{"name":"Score","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"CriticalPath","index":0,"aggr":"sum"},"yAxis":{"name":"Score","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{"dagName":""},"forms":{"dagName":{"name":"dagName","defaultValue":"","hidden":true}}},"jobName":"paragraph_1470997772800_-1526189619","id":"20160405-132729_1861451876","result":{"code":"ERROR","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:262"},{"dateUpdated":"2016-08-12T10:29:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1470997772800_-1526189619","id":"20160405-132729_1119017199","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-08-12T10:29:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:263"}],"name":"Tez_ATS_JobAnalyzer","id":"2BVQT2RUM","angularObjects":{"2BUFW2B44:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}